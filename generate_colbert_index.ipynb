{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColBERTv2: Indexing & Search Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the relevant classes. As we'll see below, `Indexer` and `Searcher` are the key actors here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, '../')\n",
    "os.chdir('ColBERT')\n",
    "\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow here assumes an IR dataset: a set of queries and a corresponding collection of passages.\n",
    "\n",
    "The classes `Queries` and `Collection` provide a convenient interface for working with such datasets.\n",
    "\n",
    "We will use the *dev set* of the **LoTTE benchmark** we recently introduced in the ColBERTv2 paper. The dev and test sets contain several domain-specific corpora, and we'll use the smallest dev set corpus, namely `lifestyle:dev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-24 21:31:43--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 405924985 (387M) [application/octet-stream]\n",
      "Saving to: ‘downloads/colbertv2.0.tar.gz’\n",
      "\n",
      "colbertv2.0.tar.gz  100%[===================>] 387.12M  4.92MB/s    in 74s     \n",
      "\n",
      "2022-05-24 21:32:57 (5.23 MB/s) - ‘downloads/colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
      "\n",
      "colbertv2.0/\n",
      "colbertv2.0/artifact.metadata\n",
      "colbertv2.0/vocab.txt\n",
      "colbertv2.0/tokenizer.json\n",
      "colbertv2.0/special_tokens_map.json\n",
      "colbertv2.0/tokenizer_config.json\n",
      "colbertv2.0/config.json\n",
      "colbertv2.0/pytorch_model.bin\n",
      "--2022-05-24 21:33:02--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/lotte.tar.gz\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3576167599 (3.3G) [application/octet-stream]\n",
      "Saving to: ‘downloads/lotte.tar.gz’\n",
      "\n",
      "lotte.tar.gz        100%[===================>]   3.33G  5.00MB/s    in 11m 17s \n",
      "\n",
      "2022-05-24 21:44:19 (5.04 MB/s) - ‘downloads/lotte.tar.gz’ saved [3576167599/3576167599]\n",
      "\n",
      "lotte/\n",
      "lotte/science/\n",
      "lotte/science/test/\n",
      "lotte/science/test/questions.search.tsv\n",
      "lotte/science/test/questions.forum.tsv\n",
      "lotte/science/test/collection.tsv\n",
      "lotte/science/test/qas.forum.jsonl\n",
      "lotte/science/test/metadata.jsonl\n",
      "lotte/science/test/qas.search.jsonl\n",
      "lotte/science/dev/\n",
      "lotte/science/dev/questions.search.tsv\n",
      "lotte/science/dev/questions.forum.tsv\n",
      "lotte/science/dev/collection.tsv\n",
      "lotte/science/dev/qas.forum.jsonl\n",
      "lotte/science/dev/metadata.jsonl\n",
      "lotte/science/dev/qas.search.jsonl\n",
      "lotte/writing/\n",
      "lotte/writing/test/\n",
      "lotte/writing/test/questions.search.tsv\n",
      "lotte/writing/test/questions.forum.tsv\n",
      "lotte/writing/test/collection.tsv\n",
      "lotte/writing/test/qas.forum.jsonl\n",
      "lotte/writing/test/metadata.jsonl\n",
      "lotte/writing/test/qas.search.jsonl\n",
      "lotte/writing/dev/\n",
      "lotte/writing/dev/questions.search.tsv\n",
      "lotte/writing/dev/questions.forum.tsv\n",
      "lotte/writing/dev/collection.tsv\n",
      "lotte/writing/dev/qas.forum.jsonl\n",
      "lotte/writing/dev/metadata.jsonl\n",
      "lotte/writing/dev/qas.search.jsonl\n",
      "lotte/recreation/\n",
      "lotte/recreation/test/\n",
      "lotte/recreation/test/questions.search.tsv\n",
      "lotte/recreation/test/questions.forum.tsv\n",
      "lotte/recreation/test/collection.tsv\n",
      "lotte/recreation/test/qas.forum.jsonl\n",
      "lotte/recreation/test/metadata.jsonl\n",
      "lotte/recreation/test/qas.search.jsonl\n",
      "lotte/recreation/dev/\n",
      "lotte/recreation/dev/questions.search.tsv\n",
      "lotte/recreation/dev/questions.forum.tsv\n",
      "lotte/recreation/dev/collection.tsv\n",
      "lotte/recreation/dev/qas.forum.jsonl\n",
      "lotte/recreation/dev/metadata.jsonl\n",
      "lotte/recreation/dev/qas.search.jsonl\n",
      "lotte/lifestyle/\n",
      "lotte/lifestyle/test/\n",
      "lotte/lifestyle/test/questions.search.tsv\n",
      "lotte/lifestyle/test/questions.forum.tsv\n",
      "lotte/lifestyle/test/collection.tsv\n",
      "lotte/lifestyle/test/qas.forum.jsonl\n",
      "lotte/lifestyle/test/metadata.jsonl\n",
      "lotte/lifestyle/test/qas.search.jsonl\n",
      "lotte/lifestyle/dev/\n",
      "lotte/lifestyle/dev/questions.search.tsv\n",
      "lotte/lifestyle/dev/questions.forum.tsv\n",
      "lotte/lifestyle/dev/collection.tsv\n",
      "lotte/lifestyle/dev/qas.forum.jsonl\n",
      "lotte/lifestyle/dev/metadata.jsonl\n",
      "lotte/lifestyle/dev/qas.search.jsonl\n",
      "lotte/evaluate_lotte_rankings.py\n",
      "lotte/technology/\n",
      "lotte/technology/test/\n",
      "lotte/technology/test/questions.search.tsv\n",
      "lotte/technology/test/questions.forum.tsv\n",
      "lotte/technology/test/collection.tsv\n",
      "lotte/technology/test/qas.forum.jsonl\n",
      "lotte/technology/test/metadata.jsonl\n",
      "lotte/technology/test/qas.search.jsonl\n",
      "lotte/technology/dev/\n",
      "lotte/technology/dev/questions.search.tsv\n",
      "lotte/technology/dev/questions.forum.tsv\n",
      "lotte/technology/dev/collection.tsv\n",
      "lotte/technology/dev/qas.forum.jsonl\n",
      "lotte/technology/dev/metadata.jsonl\n",
      "lotte/technology/dev/qas.search.jsonl\n",
      "lotte/pooled/\n",
      "lotte/pooled/test/\n",
      "lotte/pooled/test/questions.search.tsv\n",
      "lotte/pooled/test/questions.forum.tsv\n",
      "lotte/pooled/test/collection.tsv\n",
      "lotte/pooled/test/qas.forum.jsonl\n",
      "lotte/pooled/test/qas.search.jsonl\n",
      "lotte/pooled/dev/\n",
      "lotte/pooled/dev/questions.search.tsv\n",
      "lotte/pooled/dev/questions.forum.tsv\n",
      "lotte/pooled/dev/collection.tsv\n",
      "lotte/pooled/dev/qas.forum.jsonl\n",
      "lotte/pooled/dev/qas.search.jsonl\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p downloads/\n",
    "\n",
    "# ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
    "!wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P downloads/\n",
    "!tar -xvzf downloads/colbertv2.0.tar.gz -C downloads/\n",
    "\n",
    "# The LoTTE dev and test sets (3.4GB compressed)\n",
    "!wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/lotte.tar.gz -P downloads/\n",
    "!tar -xvzf downloads/lotte.tar.gz -C downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 24, 23:04:50] #> Loading the queries from downloads/lotte/lifestyle/dev/questions.search.tsv ...\n",
      "[May 24, 23:04:50] #> Got 417 queries. All QIDs are unique.\n",
      "\n",
      "[May 24, 23:04:50] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Loaded 417 queries and 268,893 passages'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataroot = 'downloads/lotte'\n",
    "dataset = 'lifestyle'\n",
    "datasplit = 'dev'\n",
    "\n",
    "queries = os.path.join(dataroot, dataset, datasplit, 'questions.search.tsv')\n",
    "collection = os.path.join(dataroot, dataset, datasplit, 'collection.tsv')\n",
    "\n",
    "queries = Queries(path=queries)\n",
    "collection = Collection(path=collection)\n",
    "\n",
    "f'Loaded {len(queries)} queries and {len(collection):,} passages'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loaded 417 queries and 269k passages. Let's inspect one query and one passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection= collection[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are blossom end rot tomatoes edible?\n",
      "\n",
      "I'd say you shouldn't. She doesn't even let you touch her. If she has problems in the new place, she can't ask help from you. She might be too old to compete with the other cats from scratch. Now, she should have a territory of her own, and it is easier to defend than claim new one. She might have other people giving out food. The best you can do is to contact the neighbours to offer food at least from time to time, at a point close to your current feeding point. Even if they do it one-two times a week, it would help the cat a lot. Also, try to contact the new residents of your place, you never know when you meet a cat lover. The odds are stacked against moving the cat, but it doesn't matter much. Bad things happen to feral cats all the time and it might happen to her whether you move her or leave her. I hope this helps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(queries[24])\n",
    "print()\n",
    "print(collection[9999])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "For efficient search, we can pre-compute the ColBERT representation of each passage and index them.\n",
    "\n",
    "Below, the `Indexer` take a model checkpoint and writes a (compressed) index to disk. We then prepare a `Searcher` for retrieval from this index.\n",
    "\n",
    "(With four Titan V GPUs, indexing should take about 13 minutes. The output is fairly long/ugly at the moment!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300   # truncate passages at 300 tokens\n",
    "\n",
    "checkpoint = 'downloads/colbertv2.0'\n",
    "index_name = f'{dataset}.{datasplit}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lifestyle.dev.2bits'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<colbert.data.collection.Collection at 0x7f9d10145280>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[May 24, 23:06:08] #> Note: Output directory /home/zhanj289/projects/cs224u_nlu_project/ColBERT/docs/experiments/notebook/indexes/lifestyle.dev.2bits already exists\n",
      "\n",
      "\n",
      "[May 24, 23:06:08] #> Will delete 10 files already at /home/zhanj289/projects/cs224u_nlu_project/ColBERT/docs/experiments/notebook/indexes/lifestyle.dev.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"nprobe\": 2,\n",
      "    \"ncandidates\": 8192,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"save_every\": null,\n",
      "    \"resume\": false,\n",
      "    \"warmup\": 20000,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 64,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"downloads\\/colbertv2.0\",\n",
      "    \"triples\": \"\\/future\\/u\\/okhattab\\/root\\/unit\\/experiments\\/2021.10\\/downstream.distillation.round2.2_score\\/round2.nway6.cosine.ib\\/examples.64.json\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": \"downloads\\/lotte\\/lifestyle\\/dev\\/collection.tsv\"\n",
      "    },\n",
      "    \"queries\": \"\\/future\\/u\\/okhattab\\/data\\/MSMARCO\\/queries.train.tsv\",\n",
      "    \"index_name\": \"lifestyle.dev.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/zhanj289\\/projects\\/cs224u_nlu_project\\/ColBERT\\/docs\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2022-05\\/24\\/21.31.34\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[May 24, 23:07:53] [0] \t\t # of sampled PIDs = 90887 \t sampled_pids[:3] = [218428, 5331, 156573]\n",
      "[May 24, 23:07:53] [0] \t\t #> Encoding 90887 passages..\n",
      "[May 24, 23:20:10] [0] \t\t avg_doclen_est = 151.3106231689453 \t len(local_sample) = 90,887\n",
      "[May 24, 23:20:20] [0] \t\t Creaing 65,536 partitions.\n",
      "[May 24, 23:20:20] [0] \t\t *Estimated* 40,686,367 embeddings.\n",
      "[May 24, 23:20:20] [0] \t\t #> Saving the indexing plan to /home/zhanj289/projects/cs224u_nlu_project/ColBERT/docs/experiments/notebook/indexes/lifestyle.dev.2bits/plan.json ..\n",
      "Clustering 13702168 points in 128D to 65536 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 1.07 s\n",
      "  Iteration 19 (1853.24 s, search 1844.34 s): objective=3.40397e+06 imbalance=1.250 nsplit=0       \n",
      "[0.035, 0.037, 0.035, 0.034, 0.034, 0.036, 0.036, 0.034, 0.034, 0.034, 0.034, 0.034, 0.037, 0.037, 0.035, 0.037, 0.032, 0.036, 0.035, 0.034, 0.034, 0.036, 0.034, 0.034, 0.034, 0.034, 0.035, 0.034, 0.039, 0.037, 0.036, 0.039, 0.037, 0.034, 0.034, 0.033, 0.036, 0.035, 0.036, 0.044, 0.036, 0.034, 0.036, 0.036, 0.036, 0.034, 0.032, 0.038, 0.037, 0.035, 0.034, 0.034, 0.04, 0.036, 0.034, 0.034, 0.038, 0.038, 0.045, 0.034, 0.035, 0.037, 0.035, 0.036, 0.038, 0.037, 0.039, 0.035, 0.034, 0.035, 0.038, 0.031, 0.034, 0.036, 0.034, 0.036, 0.037, 0.037, 0.036, 0.037, 0.038, 0.035, 0.036, 0.037, 0.033, 0.036, 0.036, 0.033, 0.033, 0.038, 0.035, 0.039, 0.034, 0.037, 0.036, 0.036, 0.039, 0.033, 0.036, 0.035, 0.033, 0.037, 0.035, 0.036, 0.038, 0.033, 0.036, 0.033, 0.035, 0.035, 0.036, 0.035, 0.037, 0.035, 0.036, 0.035, 0.037, 0.036, 0.034, 0.037, 0.034, 0.035, 0.037, 0.036, 0.034, 0.037, 0.036, 0.034]\n",
      "[May 24, 23:51:21] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[May 24, 23:51:21] #> Got bucket_cutoffs = tensor([-0.0287,  0.0002,  0.0291], device='cuda:0') and bucket_weights = tensor([-0.0504, -0.0134,  0.0137,  0.0509], device='cuda:0')\n",
      "[May 24, 23:51:21] avg_residual = 0.03564453125\n",
      "[May 24, 23:51:21] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 24, 23:54:31] [0] \t\t #> Saving chunk 0: \t 25,000 passages and 3,779,083 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:20, 200.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 24, 23:54:41] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 24, 23:57:51] [0] \t\t #> Saving chunk 1: \t 25,000 passages and 4,073,198 embeddings. From #25,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [06:37, 198.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 24, 23:57:58] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:01:19] [0] \t\t #> Saving chunk 2: \t 25,000 passages and 4,442,623 embeddings. From #50,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [10:06, 203.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:01:28] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:05:04] [0] \t\t #> Saving chunk 3: \t 25,000 passages and 4,047,185 embeddings. From #75,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [13:51, 211.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:05:12] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:08:48] [0] \t\t #> Saving chunk 4: \t 25,000 passages and 3,953,755 embeddings. From #100,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [17:34, 216.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:08:56] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:12:30] [0] \t\t #> Saving chunk 5: \t 25,000 passages and 3,347,195 embeddings. From #125,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [21:14, 217.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:12:36] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:15:43] [0] \t\t #> Saving chunk 6: \t 25,000 passages and 3,441,185 embeddings. From #150,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [24:27, 209.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:15:49] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:19:16] [0] \t\t #> Saving chunk 7: \t 25,000 passages and 3,597,393 embeddings. From #175,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [28:02, 210.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:19:23] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:22:42] [0] \t\t #> Saving chunk 8: \t 25,000 passages and 3,698,831 embeddings. From #200,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [31:27, 209.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:22:48] [0] \t\t #> Encoding 25000 passages..\n",
      "[May 25, 00:26:00] [0] \t\t #> Saving chunk 9: \t 25,000 passages and 3,739,499 embeddings. From #225,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [34:46, 205.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:26:07] [0] \t\t #> Encoding 18893 passages..\n",
      "[May 25, 00:28:48] [0] \t\t #> Saving chunk 10: \t 18,893 passages and 2,636,639 embeddings. From #250,000 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [37:32, 204.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:29:00] [0] \t\t #> Saving the indexing metadata to /home/zhanj289/projects/cs224u_nlu_project/ColBERT/docs/experiments/notebook/indexes/lifestyle.dev.2bits/metadata.json ..\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "with Run().context(RunConfig(nranks=1, experiment='notebook')):  # nranks specifies the number of GPUs to use.\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=collection, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zhanj289/projects/cs224u_nlu_project/ColBERT/docs/experiments/notebook/indexes/lifestyle.dev.2bits'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.get_index() # You can get the absolute path of the index, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "Having built the index and prepared our `searcher`, we can search for individual query strings.\n",
    "\n",
    "We can use the `queries` set we loaded earlier — or you can supply your own questions. Feel free to get creative! But keep in mind this set of ~300k lifestyle passages can only answer a small, focused set of questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 00:29:06] #> Loading collection...\n",
      "0M \n",
      "[May 25, 00:29:12] #> Building the emb2pid mapping..\n",
      "[May 25, 00:29:12] len(self.emb2pid) = 40756586\n"
     ]
    }
   ],
   "source": [
    "# To create the searcher using its relative name (i.e., not a full path), set\n",
    "# experiment=value_used_for_indexing in the RunConfig.\n",
    "with Run().context(RunConfig(experiment='notebook')):\n",
    "    searcher = Searcher(index=index_name)\n",
    "\n",
    "\n",
    "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
    "# config=ColBERTConfig(nprobe=.., ncandidates=..) argument. The default (2, 8192) works well,\n",
    "# but you can trade away some latency to gain more extensive search with (4, 16384).\n",
    "# Conversely, you can get faster search with (1, 4096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3736, 7629, 656, 2724, 314],\n",
       " [1, 2, 3, 4, 5],\n",
       " [15.3125, 14.84375, 14.6875, 14.6484375, 14.5703125])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268893"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(searcher.collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First of all, dogs are dogs. The all have the same basic needs. And every dog can be trained. And even dogs of the same breed can be really different in behavior and character. But, you are right, not every breed is equally suitable for every task or life circumstances and the purebreeds are known for unique qualities. I want to bring the dog to a small (60-70 SqM) apartment. My main concern is the behavior. Can they be trained like a purebred? (Labs, Goldens, Border Collies, Aussies,...) These breeds you mentioned are really different. Border Collies and Aussies were bred for herding tasks. That means, they are highly intelligent, very sensible, need very much exercise, and are really self-confident. If you let them, they are working, running or playing until they die. They don\\'t give up. They recognize every motion far away, because they were bred to see, if any sheep is running away. Labs and Goldens are bred for waterfowling and hunting. They are intelligent as well, need exercise and are self-confident. They were bred to hunt the birds or other animals, but bring them to the hunter without hurting the prey. So they are really soft with their mouth. And they are much more calm than the herding dogs and not as sensible. So they are known for being excellent family dogs. So all the breeds you mentioned are not made for small apartments, but they can be happy there, if the owner has the time and knowledge to handle their needs. Another thing is, you can\\'t compare \"the purebreeds\" with \"the mixed breeds\". Every breed has its qualities, things they easily learn or like to do and their weaknesses or possible problems because of the history. And keep in mind, every dog is unique and can vary from the characteristics their breeds are known for. Now I\\'m wondering if is it OK to adopt a pup from farmers who live in villages and their dogs are clearly from no specific breeds and their parents have been herding shepherd dogs in our local environment? (Western Iran) The dogs are for herding purposes. So they are middle sized, I guess, because they need to be strong enough to handle the herded animals, but I think they will not be too big, because they would need to much to eat and wouldn\\'t be as agile as middle sized ones. Because they are mixed breeds, they may not as specific in their behavior and character as the purebreeds. So it is more likely that one puppy is calmer than another one,or one loves to hunt while another loves to do circus lessons, one is really attentive and sensible while the sibling is a little bit sleepy. But they were used for herding, so the may be alike the Border Collies and Aussies. It is often said, that mixed breeds are intelligent and really loyal as well. They are easily trained. And some are convinced, that they are healthier than purebloods, because of their mixed genes. So if you have the time, the space, and the knowledge for a pureblood herding dog like a Border Collie, than you should be able to adopt and train a mixed herding dog as well.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.collection[5555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> what are white spots on raspberries?\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . what are white spots on raspberries?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2024,  2317,  7516,  2006, 20710,  2361, 20968,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "\t [1] \t\t 26.0 \t\t You've got a heat problem, this is UV damage or excessive heat during the ripening phase and referred to as White Drupelet syndrome (white spot). It's quite common on Raspberries during the final crops of the year as summer heat increases. Also occurs in blackberries. Last year, we had issues in the US Pacific Northwest with it, only a handful at end of season this year as we've had a cold, damp summer.\n",
      "\t [2] \t\t 26.0 \t\t White Drupelet syndrome (white spot) has the cell fully formed, no powdery residue, but the color is white instead of the normal color. It's caused by excessive sunlight (UV damage) or heat and is typically found on late season set raspberries. I view it as a normal end-of-crop phenomenon that indicates cane maintenance will be in order soon for next year's crop. Berries are entirely edible, you just won't be selling them. The first berry in the top row is a gold standard reference. White Drupelet Disorder If your berries got damp, powdery mildew can also be a late season condition. The powder will be gray and the berries mushy.\n",
      "\t [3] \t\t 19.7 \t\t The white spots are a mixture of pesticide residue and hard water stains from overhead watering in the grower's greenhouse. Wiping the leaves with a damp cloth is usually sufficient to remove the residue.\n",
      "\t [4] \t\t 19.4 \t\t They won't poison you, unless the white is actually a mould of some sort and you're sensitive to moulds, but they may not taste great - the cold has probably caused the whitening effect, and will likely have damaged the tissues/cells of the fruits. If you are going to eat them, do it as soon as possible - they'll start deteriorating rapidly now they're frost damaged. it is a little odd though - I regularly freeze raspberries, and they aren't white once defrosted, but possibly this effect is because the berries are still on the bush and weren't frozen solid.\n",
      "\t [5] \t\t 19.0 \t\t The white spots are Lichen and are harmless. Looks like an animal has been dining on the bark. My guess is rabbit.\n"
     ]
    }
   ],
   "source": [
    "query = queries[37]   # or supply your own query\n",
    "\n",
    "print(f\"#> {query}\")\n",
    "\n",
    "# Find the top-3 passages for this query\n",
    "results = searcher.search(query, k=5)\n",
    "\n",
    "# Print out the top-k retrieved passages\n",
    "for passage_id, passage_rank, passage_score in zip(*results):\n",
    "    print(f\"\\t [{passage_rank}] \\t\\t {passage_score:.1f} \\t\\t {searcher.collection[passage_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search\n",
    "\n",
    "In many applications, you have a large batch of queries and you need to maximize the overall throughput. For that, you can use the `searcher.search_all(queries, k)` method, which returns a `Ranking` object that organizes the results across all queries.\n",
    "\n",
    "(Batching provides many opportunities for higher-throughput search, though we have not implemented most of those optimizations for compressed indexes yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rankings = searcher.search_all(queries, k=5).todict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings[30]  # For query 30, a list of (passage_id, rank, score) for the top-k passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a99ac6d2deb03d0b7ced3594556c328848678d7cea021ae1b9990e15d3ad5c49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
