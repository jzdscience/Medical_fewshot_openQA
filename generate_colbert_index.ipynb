{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColBERTv2: Indexing & Search Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the relevant classes. As we'll see below, `Indexer` and `Searcher` are the key actors here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, '../')\n",
    "# sys.path.insert(0, '/home/zhanj289/projects/cs224u_nlu_project/ColBERT')\n",
    "sys.path.insert(0, './ColBERT')\n",
    "# os.chdir('ColBERT')\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'bioasq'\n",
    "\n",
    "datasplit = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow here assumes an IR dataset: a set of queries and a corresponding collection of passages.\n",
    "\n",
    "The classes `Queries` and `Collection` provide a convenient interface for working with such datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERT model pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p downloads/\n",
    "\n",
    "# ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
    "!wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P downloads/\n",
    "!tar -xvzf downloads/colbertv2.0.tar.gz -C downloads/\n",
    "\n",
    "# The LoTTE dev and test sets (3.4GB compressed)\n",
    "# !wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/lotte.tar.gz -P downloads/\n",
    "# !tar -xvzf downloads/lotte.tar.gz -C downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/bioasq/training10b.json', 'r') as f:\n",
    "    bioasq_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct collections of passages\n",
    "\n",
    "def generate_bioasq_passage(bioasq_json, length = 1024):\n",
    "    \n",
    "    bioasq_passage= []\n",
    "    eid = 0\n",
    "    \n",
    "    for i in range(len(bioasq_json['questions'])):\n",
    "\n",
    "        sample = bioasq_json['questions'][i]\n",
    "\n",
    "        if sample['type'] in ['factoid', 'list']:\n",
    "            \n",
    "            \n",
    "        # flatten all the snip and use as context\n",
    "            context = '' \n",
    "            for snip in [ele['text'].strip() for ele in sample['snippets']]:\n",
    "                snip += ' '\n",
    "                context += snip\n",
    "                \n",
    "            ## some cleaning string\n",
    "            context = context.replace('\\n', ' ')\n",
    "            \n",
    "            ## limit the length of context\n",
    "            ### Max: 4096 (for eleuther model)\n",
    "            context = context[:1024]\n",
    "            \n",
    "            # create tuple\n",
    "            context_tup = (str(eid), context)\n",
    "\n",
    "            bioasq_passage.append(context_tup)\n",
    "            # adding id\n",
    "            eid +=1\n",
    "            \n",
    "    return bioasq_passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct collections of queries\n",
    "\n",
    "def generate_bioasq_query(bioasq_json, length = 1024):\n",
    "    \n",
    "    bioasq_query= []\n",
    "    \n",
    "    eid = 0\n",
    "    \n",
    "    for i in range(len(bioasq_json['questions'])):\n",
    "        \n",
    "        \n",
    "        sample = bioasq_json['questions'][i]\n",
    "\n",
    "        if sample['type'] in ['factoid', 'list']:\n",
    "            \n",
    "            # adding id\n",
    "            \n",
    "            \n",
    "            query = sample['body']\n",
    "            \n",
    "            ## some cleaning string\n",
    "            query = query.replace('\\n', ' ')\n",
    "        # flatten all the snip and use as context\n",
    "\n",
    "            ## limit the length of context\n",
    "            ### Max: 4096 (for eleuther model)\n",
    "            query = query[:1024]\n",
    "            \n",
    "            # create \n",
    "            new_query = (str(eid), query)\n",
    "            \n",
    "            bioasq_query.append(new_query)\n",
    "            \n",
    "            eid += 1\n",
    "            \n",
    "    return bioasq_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how long? probably starting from 1024\n",
    "bioasq_passage = generate_bioasq_passage(bioasq_json, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_query = generate_bioasq_query(bioasq_json, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/bioasq_passage.tsv', 'w+', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output, delimiter='\\t')\n",
    "\n",
    "    csv_output.writerows(bioasq_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/bioasq_query.tsv', 'w+', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output, delimiter='\\t')\n",
    "\n",
    "    csv_output.writerows(bioasq_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jun 04, 22:19:22] #> Loading the queries from experiments/bioasq_query.tsv ...\n",
      "[Jun 04, 22:19:22] #> Got 2068 queries. All QIDs are unique.\n",
      "\n",
      "[Jun 04, 22:19:22] #> Loading collection...\n",
      "0M \n"
     ]
    }
   ],
   "source": [
    "queries = Queries(path='experiments/bioasq_query.tsv')\n",
    "collection = Collection(path='experiments/bioasq_passage.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment of which disease was investigated in the MR CLEAN study?\n",
      "\n",
      "Exome Sequencing Identifies a Rare HSPG2 Variant Associated with Familial Idiopathic Scoliosis. Overall, these findings demonstrate a novel role for kif6 in spinal development and identify a new candidate gene for human idiopathic scoliosis. HL1 is of interest, as it encodes an axon guidance protein related to Robo3. Mutations in the Robo3 protein cause horizontal gaze palsy with progressive scoliosis (HGPPS), a rare disease marked by severe scoliosis. Other top associations in our GWAS were with SNPs in the DSCAM gene encoding an axon guidance protein in the same structural class with Chl1 and Robo3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(queries[24])\n",
    "print()\n",
    "print(collection[200])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "For efficient search, we can pre-compute the ColBERT representation of each passage and index them.\n",
    "\n",
    "Below, the `Indexer` take a model checkpoint and writes a (compressed) index to disk. We then prepare a `Searcher` for retrieval from this index.\n",
    "\n",
    "(With four Titan V GPUs, indexing should take about 13 minutes. The output is fairly long/ugly at the moment!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300   # truncate passages at 300 tokens\n",
    "\n",
    "checkpoint = 'ColBERT/docs/downloads/colbertv2.0'\n",
    "index_name = f'{dataset}.{datasplit}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bioasq.all.2bits'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Jun 04, 22:19:29] #> Note: Output directory /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits already exists\n",
      "\n",
      "\n",
      "[Jun 04, 22:19:29] #> Will delete 10 files already at /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"nprobe\": 2,\n",
      "    \"ncandidates\": 8192,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"save_every\": null,\n",
      "    \"resume\": false,\n",
      "    \"warmup\": 20000,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 64,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"ColBERT\\/docs\\/downloads\\/colbertv2.0\",\n",
      "    \"triples\": \"\\/future\\/u\\/okhattab\\/root\\/unit\\/experiments\\/2021.10\\/downstream.distillation.round2.2_score\\/round2.nway6.cosine.ib\\/examples.64.json\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": \"experiments\\/bioasq_passage.tsv\"\n",
      "    },\n",
      "    \"queries\": \"\\/future\\/u\\/okhattab\\/data\\/MSMARCO\\/queries.train.tsv\",\n",
      "    \"index_name\": \"bioasq.all.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/zhanj289\\/projects\\/cs224u_nlu_project\\/experiments\",\n",
      "    \"experiment\": \"bioasq\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2022-06\\/04\\/22.10.41\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jun 04, 22:20:10] [0] \t\t # of sampled PIDs = 2068 \t sampled_pids[:3] = [1706, 41, 1223]\n",
      "[Jun 04, 22:20:10] [0] \t\t #> Encoding 2068 passages..\n",
      "[Jun 04, 22:20:27] [0] \t\t avg_doclen_est = 182.8452606201172 \t len(local_sample) = 2,068\n",
      "[Jun 04, 22:20:27] [0] \t\t Creaing 8,192 partitions.\n",
      "[Jun 04, 22:20:27] [0] \t\t *Estimated* 378,123 embeddings.\n",
      "[Jun 04, 22:20:27] [0] \t\t #> Saving the indexing plan to /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits/plan.json ..\n",
      "Clustering 328124 points in 128D to 8192 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.03 s\n",
      "  Iteration 19 (7.13 s, search 6.89 s): objective=70176.2 imbalance=1.420 nsplit=0       \n",
      "[0.034, 0.036, 0.035, 0.031, 0.032, 0.033, 0.035, 0.032, 0.032, 0.034, 0.033, 0.032, 0.035, 0.033, 0.031, 0.034, 0.03, 0.032, 0.031, 0.033, 0.033, 0.033, 0.033, 0.032, 0.032, 0.034, 0.035, 0.033, 0.032, 0.036, 0.031, 0.037, 0.034, 0.033, 0.033, 0.03, 0.036, 0.034, 0.033, 0.04, 0.034, 0.034, 0.033, 0.034, 0.031, 0.032, 0.033, 0.037, 0.033, 0.032, 0.031, 0.034, 0.035, 0.033, 0.032, 0.033, 0.04, 0.034, 0.037, 0.033, 0.033, 0.035, 0.033, 0.037, 0.035, 0.034, 0.033, 0.035, 0.031, 0.032, 0.035, 0.031, 0.033, 0.033, 0.032, 0.037, 0.034, 0.033, 0.034, 0.034, 0.033, 0.034, 0.034, 0.035, 0.03, 0.034, 0.032, 0.036, 0.03, 0.036, 0.031, 0.036, 0.032, 0.034, 0.034, 0.034, 0.038, 0.033, 0.032, 0.033, 0.034, 0.036, 0.034, 0.032, 0.034, 0.032, 0.032, 0.031, 0.033, 0.032, 0.035, 0.034, 0.034, 0.031, 0.035, 0.031, 0.033, 0.034, 0.032, 0.032, 0.032, 0.034, 0.035, 0.037, 0.032, 0.036, 0.033, 0.031]\n",
      "[Jun 04, 22:20:36] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jun 04, 22:20:36] #> Got bucket_cutoffs = tensor([-2.6276e-02,  2.3484e-05,  2.6428e-02], device='cuda:0') and bucket_weights = tensor([-0.0469, -0.0121,  0.0122,  0.0471], device='cuda:0')\n",
      "[Jun 04, 22:20:36] avg_residual = 0.033477783203125\n",
      "[Jun 04, 22:20:36] [0] \t\t #> Encoding 2068 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jun 04, 22:20:52] [0] \t\t #> Saving chunk 0: \t 2,068 passages and 378,124 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:19, 19.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jun 04, 22:20:55] [0] \t\t #> Saving the indexing metadata to /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits/metadata.json ..\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "with Run().context(RunConfig(nranks=1, experiment='bioasq')):  # nranks specifies the number of GPUs to use.\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=collection, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.get_index() # You can get the absolute path of the index, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "Having built the index and prepared our `searcher`, we can search for individual query strings.\n",
    "\n",
    "We can use the `queries` set we loaded earlier — or you can supply your own questions. Feel free to get creative! But keep in mind this set of ~300k lifestyle passages can only answer a small, focused set of questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jun 04, 22:20:57] #> Loading collection...\n",
      "0M \n",
      "[Jun 04, 22:21:02] #> Building the emb2pid mapping..\n",
      "[Jun 04, 22:21:02] len(self.emb2pid) = 378124\n"
     ]
    }
   ],
   "source": [
    "# To create the searcher using its relative name (i.e., not a full path), set\n",
    "# experiment=value_used_for_indexing in the RunConfig.\n",
    "with Run().context(RunConfig(experiment='bioasq')):\n",
    "    searcher = Searcher(index=index_name)\n",
    "\n",
    "\n",
    "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
    "# config=ColBERTConfig(nprobe=.., ncandidates=..) argument. The default (2, 8192) works well,\n",
    "# but you can trade away some latency to gain more extensive search with (4, 16384).\n",
    "# Conversely, you can get faster search with (1, 4096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2068"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(searcher.collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.collection[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Which enzyme is targeted by the drug Imetelstat?\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Which enzyme is targeted by the drug Imetelstat?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2029,  9007,  2003,  9416,  2011,  1996,  4319, 10047,\n",
      "        12870,  4877, 29336,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "\t [1] \t\t 22.3 \t\t Imetelstat (a telomerase antagonist) exerts off‑target effects on the cytoskeleton. imetelstat sodium (GRN163L), is a 13-mer oligonucleotide N3'→P5' thio-phosphoramidate lipid conjugate, which represents the latest generation of telomerase inhibitors targeting the template region of the human functional telomerase RNA (hTR) subunit. In preclinical trials, this compound has been found to inhibit telomerase activity in multiple cancer cell lines, as well as in vivo xenograft mouse models. In addition to the inhibition of telomerase activity in cancer cell lines, GRN163L causes morphological cell rounding changes, independent of hTR expression or telomere length. We sought to evaluate the potential of the thio-phosphoramidate oligonucleotide inhibitor of telomerase, imetelstat, as a drug candidate for treatment of esophageal cancer. Our results showed that imetelstat inhibited telomerase activity in a dose-dependent manner in esophageal cancer cells Furthermore, long-term treatment with imetelstat decreased cell\n",
      "\t [2] \t\t 19.1 \t\t The telomerase inhibitor imetelstat alone, and in combination with trastuzumab, decreases the cancer stem cell population and self-renewal of HER2+ breast cancer cells. The purpose of this study was to investigate the effects of a telomerase antagonistic oligonucleotide, imetelstat (GRN163L), on CSC and non-CSC populations of HER2(+) breast cancer cell lines. Imetelstat inhibited telomerase activity in both subpopulations. Telomerase inhibitor Imetelstat (GRN163L) limits the lifespan of human pancreatic cancer cells. GRN163L (Imetelstat) is a lipid-conjugated N3'→P5' thio-phosphoramidate oligonucleotide that blocks the template region of telomerase. We evaluated the effect of the telomerase inhibitor imetelstat in preclinical models of MRT. Treatment with imetelstat resulted in inhibition of telomerase activity, marked telomere shortening, and activation of the DNA damage response pathway, as measured by formation of γ-H2AX nuclear foci, phosphorylation of ATM, and phosphorylation of TP53. The activity of ime\n",
      "\t [3] \t\t 17.6 \t\t The flavoenzyme dihydroorotate dehydrogenase (DHODH) catalyzes the fourth reaction of the de novo pyrimidine biosynthetic pathway, which exerts vital functions in the cells, especially within DNA and RNA biosynthesis. Human dihydroorotate dehydrogenase (HsDHODH) is a key enzyme of pyrimidine de novo biosynthesis pathway Dihydroorotate dehydrogenase (DHODH) mediates the fourth step of de novo pyrimidine biosynthesis and is a proven drug target for inducing immunosuppression in therapy of human disease as well as a rapidly emerging drug target for treatment of malaria. This review focuses on recent studies to exploit the fourth enzyme in the de novo pyrimidine biosynthetic pathway of P. falciparum, dihydroorotate dehydrogenase (PfDHODH), as a new target for drug discovery. The flavoenzyme dihydroorotate dehydrogenase catalyzes the stereoselective oxidation of (S)-dihydroorotate to orotate in the fourth of the six conserved enzymatic reactions involved in the de novo pyrimidine biosynthetic pathway. A set of com\n",
      "\t [4] \t\t 17.2 \t\t Expert opinion: Drugs in Phase III clinical development for AD include one inhibitor of the β-secretase cleaving enzyme (BACE) (verubecestat), three anti-Aβ monoclonal antibodies (solanezumab, gantenerumab, and aducanumab), an inhibitor of receptor for advanced glycation end products (RAGE) (azeliragon) and the combination of cromolyn sodium and ibuprofen (ALZT-OP1).\n",
      "\t [5] \t\t 16.6 \t\t Finally, MLN4924, an investigational small molecule inhibitor of NEDD8-activating enzyme (NAE) that inhibits CRL, suppresses in vitro migration, proliferation and tube formation, as well as in vivo angiogenesis and tumorigenesis. MLN4924, a small molecule inhibitor of NEDD8 activating enzyme (NAE), has been reported to elicit an anti-tumor effect on various malignancies. The more targeted impact of NEDD8-activating enzyme on protein degradation prompted us to study MLN4924, an investigational NEDD8-activating enzyme inhibitor, in preclinical multiple myeloma models. A gatekeeper residue for NEDD8-activating enzyme inhibition by MLN4924. Treatment-emergent mutations in NAEβ confer resistance to the NEDD8-activating enzyme inhibitor MLN4924. Quantifiable analysis of cellular pathway inhibition of a Nedd8-activating enzyme inhibitor, MLN4924, using AlphaScreen. Cellular effects of a Nedd8-activating enzyme (NAE) inhibitor, MLN4924, using the AlphaScreen format were explored. Quantitative proteomic analysis of ce\n"
     ]
    }
   ],
   "source": [
    "query = queries[37]   # or supply your own query\n",
    "\n",
    "print(f\"#> {query}\")\n",
    "\n",
    "# Find the top-3 passages for this query\n",
    "results = searcher.search(query, k=5)\n",
    "\n",
    "# Print out the top-k retrieved passages\n",
    "for passage_id, passage_rank, passage_score in zip(*results):\n",
    "    print(f\"\\t [{passage_rank}] \\t\\t {passage_score:.1f} \\t\\t {searcher.collection[passage_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search\n",
    "\n",
    "In many applications, you have a large batch of queries and you need to maximize the overall throughput. For that, you can use the `searcher.search_all(queries, k)` method, which returns a `Ranking` object that organizes the results across all queries.\n",
    "\n",
    "(Batching provides many opportunities for higher-throughput search, though we have not implemented most of those optimizations for compressed indexes yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2068/2068 [00:19<00:00, 105.99it/s]\n"
     ]
    }
   ],
   "source": [
    "rankings = searcher.search_all(queries, k=5).todict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings[30]  # For query 30, a list of (passage_id, rank, score) for the top-k passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haha\n"
     ]
    }
   ],
   "source": [
    "print('haha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a99ac6d2deb03d0b7ced3594556c328848678d7cea021ae1b9990e15d3ad5c49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
