{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColBERTv2: Indexing & Search Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the relevant classes. As we'll see below, `Indexer` and `Searcher` are the key actors here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, '../')\n",
    "# sys.path.insert(0, '/home/zhanj289/projects/cs224u_nlu_project/ColBERT')\n",
    "sys.path.insert(0, './ColBERT')\n",
    "# os.chdir('ColBERT')\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'bioasq'\n",
    "\n",
    "datasplit = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow here assumes an IR dataset: a set of queries and a corresponding collection of passages.\n",
    "\n",
    "The classes `Queries` and `Collection` provide a convenient interface for working with such datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERT model pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p downloads/\n",
    "\n",
    "# ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
    "!wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P downloads/\n",
    "!tar -xvzf downloads/colbertv2.0.tar.gz -C downloads/\n",
    "\n",
    "# The LoTTE dev and test sets (3.4GB compressed)\n",
    "# !wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/lotte.tar.gz -P downloads/\n",
    "# !tar -xvzf downloads/lotte.tar.gz -C downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/bioasq/training10b.json', 'r') as f:\n",
    "    bioasq_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct collections of passages\n",
    "\n",
    "def generate_bioasq_passage(bioasq_json, length = 1024):\n",
    "    \n",
    "    bioasq_passage= []\n",
    "    eid = 0\n",
    "    \n",
    "    for i in range(len(bioasq_json['questions'])):\n",
    "\n",
    "        sample = bioasq_json['questions'][i]\n",
    "\n",
    "        if sample['type'] in ['factoid', 'list']:\n",
    "            \n",
    "            \n",
    "        # flatten all the snip and use as context\n",
    "            context = '' \n",
    "            for snip in [ele['text'].strip() for ele in sample['snippets']]:\n",
    "                snip += ' '\n",
    "                context += snip\n",
    "                \n",
    "            ## some cleaning string\n",
    "            context = context.replace('\\n', ' ')\n",
    "            \n",
    "            ## limit the length of context\n",
    "            ### Max: 4096 (for eleuther model)\n",
    "            context = context[:1024]\n",
    "            \n",
    "            # create tuple\n",
    "            context_tup = (str(eid), context)\n",
    "\n",
    "            bioasq_passage.append(context_tup)\n",
    "            # adding id\n",
    "            eid +=1\n",
    "            \n",
    "    return bioasq_passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct collections of queries\n",
    "\n",
    "def generate_bioasq_query(bioasq_json, length = 1024):\n",
    "    \n",
    "    bioasq_query= []\n",
    "    \n",
    "    eid = 0\n",
    "    \n",
    "    for i in range(len(bioasq_json['questions'])):\n",
    "        \n",
    "        \n",
    "        sample = bioasq_json['questions'][i]\n",
    "\n",
    "        if sample['type'] in ['factoid', 'list']:\n",
    "            \n",
    "            # adding id\n",
    "            \n",
    "            \n",
    "            query = sample['body']\n",
    "            \n",
    "            ## some cleaning string\n",
    "            query = query.replace('\\n', ' ')\n",
    "        # flatten all the snip and use as context\n",
    "\n",
    "            ## limit the length of context\n",
    "            ### Max: 4096 (for eleuther model)\n",
    "            query = query[:1024]\n",
    "            \n",
    "            # create \n",
    "            new_query = (str(eid), query)\n",
    "            \n",
    "            bioasq_query.append(new_query)\n",
    "            \n",
    "            eid += 1\n",
    "            \n",
    "    return bioasq_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how long? probably starting from 1024\n",
    "bioasq_passage = generate_bioasq_passage(bioasq_json, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_query = generate_bioasq_query(bioasq_json, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/bioasq_passage.tsv', 'w+', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output, delimiter='\\t')\n",
    "\n",
    "    csv_output.writerows(bioasq_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/bioasq_query.tsv', 'w+', newline='') as f_output:\n",
    "    csv_output = csv.writer(f_output, delimiter='\\t')\n",
    "\n",
    "    csv_output.writerows(bioasq_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_csv('experiments/bioasq_passage.tsv', sep = '\\t')\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv('experiments/bioasq_query.tsv', sep ='\\t', header=None)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 22:30:01] #> Loading the queries from experiments/bioasq_query.tsv ...\n",
      "[May 25, 22:30:01] #> Got 2068 queries. All QIDs are unique.\n",
      "\n",
      "[May 25, 22:30:01] #> Loading collection...\n",
      "0M \n"
     ]
    }
   ],
   "source": [
    "queries = Queries(path='experiments/bioasq_query.tsv')\n",
    "collection = Collection(path='experiments/bioasq_passage.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment of which disease was investigated in the MR CLEAN study?\n",
      "\n",
      "Exome Sequencing Identifies a Rare HSPG2 Variant Associated with Familial Idiopathic Scoliosis. Overall, these findings demonstrate a novel role for kif6 in spinal development and identify a new candidate gene for human idiopathic scoliosis. HL1 is of interest, as it encodes an axon guidance protein related to Robo3. Mutations in the Robo3 protein cause horizontal gaze palsy with progressive scoliosis (HGPPS), a rare disease marked by severe scoliosis. Other top associations in our GWAS were with SNPs in the DSCAM gene encoding an axon guidance protein in the same structural class with Chl1 and Robo3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(queries[24])\n",
    "print()\n",
    "print(collection[200])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "For efficient search, we can pre-compute the ColBERT representation of each passage and index them.\n",
    "\n",
    "Below, the `Indexer` take a model checkpoint and writes a (compressed) index to disk. We then prepare a `Searcher` for retrieval from this index.\n",
    "\n",
    "(With four Titan V GPUs, indexing should take about 13 minutes. The output is fairly long/ugly at the moment!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300   # truncate passages at 300 tokens\n",
    "\n",
    "checkpoint = 'ColBERT/docs/downloads/colbertv2.0'\n",
    "index_name = f'{dataset}.{datasplit}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bioasq.all.2bits'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[May 25, 22:35:21] #> Creating directory /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"nprobe\": 2,\n",
      "    \"ncandidates\": 8192,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"save_every\": null,\n",
      "    \"resume\": false,\n",
      "    \"warmup\": 20000,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 64,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"ColBERT\\/docs\\/downloads\\/colbertv2.0\",\n",
      "    \"triples\": \"\\/future\\/u\\/okhattab\\/root\\/unit\\/experiments\\/2021.10\\/downstream.distillation.round2.2_score\\/round2.nway6.cosine.ib\\/examples.64.json\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": \"experiments\\/bioasq_passage.tsv\"\n",
      "    },\n",
      "    \"queries\": \"\\/future\\/u\\/okhattab\\/data\\/MSMARCO\\/queries.train.tsv\",\n",
      "    \"index_name\": \"bioasq.all.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/zhanj289\\/projects\\/cs224u_nlu_project\\/experiments\",\n",
      "    \"experiment\": \"bioasq\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2022-05\\/25\\/19.21.36\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[May 25, 22:36:23] [0] \t\t # of sampled PIDs = 2068 \t sampled_pids[:3] = [1706, 41, 1223]\n",
      "[May 25, 22:36:23] [0] \t\t #> Encoding 2068 passages..\n",
      "[May 25, 22:36:38] [0] \t\t avg_doclen_est = 182.8452606201172 \t len(local_sample) = 2,068\n",
      "[May 25, 22:36:38] [0] \t\t Creaing 8,192 partitions.\n",
      "[May 25, 22:36:38] [0] \t\t *Estimated* 378,123 embeddings.\n",
      "[May 25, 22:36:38] [0] \t\t #> Saving the indexing plan to /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits/plan.json ..\n",
      "Clustering 328124 points in 128D to 8192 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.02 s\n",
      "  Iteration 19 (6.51 s, search 6.32 s): objective=70176.2 imbalance=1.420 nsplit=0       \n",
      "[0.034, 0.036, 0.035, 0.031, 0.032, 0.033, 0.035, 0.032, 0.032, 0.034, 0.033, 0.032, 0.035, 0.033, 0.031, 0.034, 0.03, 0.032, 0.031, 0.033, 0.033, 0.033, 0.033, 0.032, 0.032, 0.034, 0.035, 0.033, 0.032, 0.036, 0.031, 0.037, 0.034, 0.033, 0.033, 0.03, 0.036, 0.034, 0.033, 0.04, 0.034, 0.034, 0.033, 0.034, 0.031, 0.032, 0.033, 0.037, 0.033, 0.032, 0.031, 0.034, 0.035, 0.033, 0.032, 0.033, 0.04, 0.034, 0.037, 0.033, 0.033, 0.035, 0.033, 0.037, 0.035, 0.034, 0.033, 0.035, 0.031, 0.032, 0.035, 0.031, 0.033, 0.033, 0.032, 0.037, 0.034, 0.033, 0.034, 0.034, 0.033, 0.034, 0.034, 0.035, 0.03, 0.034, 0.032, 0.036, 0.03, 0.036, 0.031, 0.036, 0.032, 0.034, 0.034, 0.034, 0.038, 0.033, 0.032, 0.033, 0.034, 0.036, 0.034, 0.032, 0.034, 0.032, 0.032, 0.031, 0.033, 0.032, 0.035, 0.034, 0.034, 0.031, 0.035, 0.031, 0.033, 0.034, 0.032, 0.032, 0.032, 0.034, 0.035, 0.037, 0.032, 0.036, 0.033, 0.031]\n",
      "[May 25, 22:36:46] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[May 25, 22:36:46] #> Got bucket_cutoffs = tensor([-2.6276e-02,  2.3484e-05,  2.6428e-02], device='cuda:0') and bucket_weights = tensor([-0.0469, -0.0121,  0.0122,  0.0471], device='cuda:0')\n",
      "[May 25, 22:36:46] avg_residual = 0.033477783203125\n",
      "[May 25, 22:36:46] [0] \t\t #> Encoding 2068 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 22:37:01] [0] \t\t #> Saving chunk 0: \t 2,068 passages and 378,124 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 22:37:04] [0] \t\t #> Saving the indexing metadata to /home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits/metadata.json ..\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "with Run().context(RunConfig(nranks=1, experiment='bioasq')):  # nranks specifies the number of GPUs to use.\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=collection, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zhanj289/projects/cs224u_nlu_project/experiments/bioasq/indexes/bioasq.all.2bits'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.get_index() # You can get the absolute path of the index, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "Having built the index and prepared our `searcher`, we can search for individual query strings.\n",
    "\n",
    "We can use the `queries` set we loaded earlier — or you can supply your own questions. Feel free to get creative! But keep in mind this set of ~300k lifestyle passages can only answer a small, focused set of questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 25, 22:37:36] #> Loading collection...\n",
      "0M \n",
      "[May 25, 22:37:41] #> Building the emb2pid mapping..\n",
      "[May 25, 22:37:41] len(self.emb2pid) = 378124\n"
     ]
    }
   ],
   "source": [
    "# To create the searcher using its relative name (i.e., not a full path), set\n",
    "# experiment=value_used_for_indexing in the RunConfig.\n",
    "with Run().context(RunConfig(experiment='bioasq')):\n",
    "    searcher = Searcher(index=index_name)\n",
    "\n",
    "\n",
    "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
    "# config=ColBERTConfig(nprobe=.., ncandidates=..) argument. The default (2, 8192) works well,\n",
    "# but you can trade away some latency to gain more extensive search with (4, 16384).\n",
    "# Conversely, you can get faster search with (1, 4096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3736, 7629, 656, 2724, 314],\n",
       " [1, 2, 3, 4, 5],\n",
       " [15.3125, 14.84375, 14.6875, 14.6484375, 14.5703125])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2068"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(searcher.collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feline leukemia virus subgroup C receptor (FLVCR1), a member of the SLC49 family of four paralogous genes, is a cell surface heme exporter, essential for erythropoiesis and systemic iron homeostasis. Feline leukemia virus subgroup C receptor (FLVCR1), a member of the SLC49 family of four paralogous genes, is a cell surface heme exporter, essential for erythropoiesis and systemic iron homeostasis. Feline leukemia virus subgroup C receptor (FLVCR1), a member of the SLC49 family of four paralogous genes, is a cell surface heme exporter, essential for erythropoiesis and systemic iron homeostasis. Disruption of FLVCR1 function blocks development of erythroid progenitors, likely due to heme toxicity. Heme is critical for a variety of cellular processes, but excess intracellular heme may result in oxidative stress and membrane injury. Feline leukemia virus subgroup C receptor (FLVCR1), a member of the SLC49 family of four paralogous genes, is a cell surface heme exporter, essential for erythropoiesis and systemic ir'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.collection[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = queries[37]   # or supply your own query\n",
    "\n",
    "print(f\"#> {query}\")\n",
    "\n",
    "# Find the top-3 passages for this query\n",
    "results = searcher.search(query, k=5)\n",
    "\n",
    "# Print out the top-k retrieved passages\n",
    "for passage_id, passage_rank, passage_score in zip(*results):\n",
    "    print(f\"\\t [{passage_rank}] \\t\\t {passage_score:.1f} \\t\\t {searcher.collection[passage_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search\n",
    "\n",
    "In many applications, you have a large batch of queries and you need to maximize the overall throughput. For that, you can use the `searcher.search_all(queries, k)` method, which returns a `Ranking` object that organizes the results across all queries.\n",
    "\n",
    "(Batching provides many opportunities for higher-throughput search, though we have not implemented most of those optimizations for compressed indexes yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2068/2068 [00:19<00:00, 105.99it/s]\n"
     ]
    }
   ],
   "source": [
    "rankings = searcher.search_all(queries, k=5).todict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings[30]  # For query 30, a list of (passage_id, rank, score) for the top-k passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a99ac6d2deb03d0b7ced3594556c328848678d7cea021ae1b9990e15d3ad5c49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
